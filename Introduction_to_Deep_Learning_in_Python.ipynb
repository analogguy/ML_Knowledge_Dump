{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Deep Learning in Python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7evZDhRSntGJ"
      },
      "source": [
        "#Coding the forward propagation algorithm\n",
        "In this exercise, we'll write code to do forward propagation (prediction) for your first neural network:\n",
        "\n",
        "\n",
        "Each data point is a customer. The first input is how many accounts they have, and the second input is how many children they have. The model will predict how many transactions the user makes in the next year. \n",
        "\n",
        "The input data has been pre-loaded as input_data, and the weights are available in a dictionary called weights. The array of weights for the first node in the hidden layer are in weights['node_0'], and the array of weights for the second node in the hidden layer are in weights['node_1'].\n",
        "\n",
        "The weights feeding into the output node are available in weights['output']."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTx4mxYcoEEm"
      },
      "source": [
        "# Calculate node 0 value: node_0_value\n",
        "node_0_value = (input_data * weights['node_0']).sum()\n",
        "\n",
        "# Calculate node 1 value: node_1_value\n",
        "node_1_value = (input_data * weights['node_1']).sum()\n",
        "\n",
        "# Put node values into array: hidden_layer_outputs\n",
        "hidden_layer_outputs = np.array([node_0_value, node_1_value])\n",
        "\n",
        "# Calculate output: output\n",
        "output = (hidden_layer_outputs * weights['output']).sum()\n",
        "\n",
        "# Print output\n",
        "print(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W7s2bNzpebZ"
      },
      "source": [
        "The rectified linear activation function (called ReLU) has been shown to lead to very high-performance networks. This function takes a single number as an input, returning 0 if the input is negative, and the input if the input is positive.\n",
        "\n",
        "Here are some examples:\n",
        "relu(3) = 3\n",
        "relu(-3) = 0\n",
        "\n",
        "activation functions help capture non-linearity in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lU_ayFL9Xy7"
      },
      "source": [
        "def relu(input):\n",
        "    '''Define your relu activation function here'''\n",
        "    # Calculate the value for the output of the relu function: output\n",
        "    output = max(0, input)\n",
        "    \n",
        "    # Return the value just calculated\n",
        "    return(output)\n",
        "\n",
        "#So max of 0 or input.    \n",
        "\n",
        "# Calculate node 0 value: node_0_output\n",
        "node_0_input = (input_data * weights['node_0']).sum()\n",
        "node_0_output = relu(node_0_input)\n",
        "\n",
        "# Calculate node 1 value: node_1_output\n",
        "node_1_input = (input_data * weights['node_1']).sum()\n",
        "node_1_output = relu(node_1_input)\n",
        "\n",
        "# Put node values into array: hidden_layer_outputs\n",
        "hidden_layer_outputs = np.array([node_0_output, node_1_output])          #Notice how relu is in a way the hidden layer, as node 0, 1 inputs are multiplied \n",
        "                                                                          #relu and considered hidden layer's output\n",
        "\n",
        "# Calculate model output (do not apply relu)\n",
        "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
        "\n",
        "# Print model output\n",
        "print(model_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xuldLS-qQgq"
      },
      "source": [
        "Applying the network to many observations/rows of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taF6X70wqTXZ"
      },
      "source": [
        "# Define predict_with_network()\n",
        "def predict_with_network(input_data_row, weights):\n",
        "\n",
        "    # Calculate node 0 value\n",
        "    node_0_input = (input_data_row * weights['node_0']).sum()\n",
        "    node_0_output = relu(node_0_input)\n",
        "\n",
        "    # Calculate node 1 value\n",
        "    node_1_input = (input_data_row * weights['node_1']).sum()\n",
        "    node_1_output = relu(node_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_layer_outputs\n",
        "    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
        "    \n",
        "    # Calculate model output\n",
        "    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum()\n",
        "    model_output = relu(input_to_final_layer)\n",
        "    \n",
        "    # Return model output\n",
        "    return(model_output)\n",
        "\n",
        "\n",
        "# Create empty list to store prediction results\n",
        "results = []\n",
        "for input_data_row in input_data:\n",
        "    # Append prediction to results\n",
        "    results.append(predict_with_network(input_data_row, weights))\n",
        "\n",
        "# Print results\n",
        "print(results)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es18qJhG01LK"
      },
      "source": [
        "Multi-layer neural networks\n",
        "In this exercise, you'll write code to do forward propagation for a neural network with 2 hidden layers. Each hidden layer has two nodes. The input data has been preloaded as input_data. The nodes in the first hidden layer are called node_0_0 and node_0_1. Their weights are pre-loaded as weights['node_0_0'] and weights['node_0_1'] respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi-3znZN03-x"
      },
      "source": [
        "def predict_with_network(input_data):\n",
        "    # Calculate node 0 in the first hidden layer\n",
        "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
        "    node_0_0_output = relu(node_0_0_input)\n",
        "\n",
        "    # Calculate node 1 in the first hidden layer\n",
        "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
        "    node_0_1_output = relu(node_0_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_0_outputs\n",
        "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
        "\n",
        "    # Calculate node 0 in the second hidden layer\n",
        "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
        "    node_1_0_output = relu(node_1_0_input)\n",
        "\n",
        "    # Calculate node 1 in the second hidden layer\n",
        "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
        "    node_1_1_output = relu(node_1_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_1_outputs\n",
        "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
        "    \n",
        "    # Calculate output here: model_output\n",
        "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
        "    \n",
        "    # Return model_output\n",
        "    return(model_output)\n",
        "\n",
        "output = predict_with_network(input_data)\n",
        "print(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQFRsSf6OLU7"
      },
      "source": [
        "Reducing error by trying different weights of nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Ty43y-OJGm"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create model_output_0 \n",
        "model_output_0 = []\n",
        "# Create model_output_1\n",
        "model_output_1 = []\n",
        "\n",
        "# Loop over input_data\n",
        "for row in input_data:\n",
        "    # Append prediction to model_output_0\n",
        "    model_output_0.append(predict_with_network(row, weights_0))\n",
        "    \n",
        "    # Append prediction to model_output_1\n",
        "    model_output_1.append(predict_with_network(row, weights_1))\n",
        "\n",
        "# Calculate the mean squared error for model_output_0: mse_0\n",
        "mse_0 = mean_squared_error(target_actuals, model_output_0)\n",
        "\n",
        "# Calculate the mean squared error for model_output_1: mse_1\n",
        "mse_1 = mean_squared_error(target_actuals, model_output_1)\n",
        "\n",
        "# Print mse_0 and mse_1\n",
        "print(\"Mean squared error with weights_0: %f\" %mse_0)\n",
        "print(\"Mean squared error with weights_1: %f\" %mse_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vjXwTRJVRTA"
      },
      "source": [
        "# Calculate the predictions: preds\n",
        "preds = (weights * input_data).sum()\n",
        "\n",
        "# Calculate the error: error\n",
        "error = preds - target\n",
        "\n",
        "# Calculate the slope: slope\n",
        "slope = 2 * input_data * error\n",
        "\n",
        "# Print the slope\n",
        "print(slope)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MwO5JzBVZiV"
      },
      "source": [
        "#Improving model weights\n",
        "Hurray! You've just calculated the slopes you need. Now it's time to use those slopes to improve your model. If you add the slopes to your weights, you will move in the right direction. However, it's possible to move too far in that direction. So you will want to take a small step in that direction first, using a lower learning rate, and verify that the model is improving."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jNfwOzzVhX8"
      },
      "source": [
        "# Set the learning rate: learning_rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Calculate the predictions: preds\n",
        "preds = (weights * input_data).sum()\n",
        "\n",
        "# Calculate the error: error\n",
        "error = preds - target\n",
        "\n",
        "# Calculate the slope: slope\n",
        "slope = 2 * input_data * error\n",
        "\n",
        "# Update the weights: weights_updated\n",
        "weights_updated = weights - learning_rate * slope\n",
        "\n",
        "# Get updated predictions: preds_updated\n",
        "preds_updated = (weights_updated * input_data).sum()\n",
        "\n",
        "# Calculate updated error: error_updated\n",
        "error_updated = preds_updated - target\n",
        "\n",
        "# Print the original error\n",
        "print(error)\n",
        "\n",
        "# Print the updated error\n",
        "print(error_updated)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh89QaQ2Vo-V"
      },
      "source": [
        "#Making multiple updates to weights\n",
        "You're now going to make multiple updates so you can dramatically improve your model weights, and see how the predictions improve with each update.\n",
        "\n",
        "To keep your code clean, there is a pre-loaded get_slope() function that takes input_data, target, and weights as arguments. There is also a get_mse() function that takes the same arguments. The input_data, target, and weights have been pre-loaded.\n",
        "\n",
        "This network does not have any hidden layers, and it goes directly from the input (with 3 nodes) to an output node. Note that weights is a single array.\n",
        "\n",
        "We have also pre-loaded matplotlib.pyplot, and the error history will be plotted after you have done your gradient descent steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBaoACJzVv58"
      },
      "source": [
        "n_updates = 20\n",
        "mse_hist = []\n",
        "\n",
        "# Iterate over the number of updates\n",
        "for i in range(n_updates):\n",
        "    # Calculate the slope: slope\n",
        "    slope = get_slope(input_data, target, weights)\n",
        "    \n",
        "    # Update the weights: weights\n",
        "    weights = weights - 0.01 * slope\n",
        "    \n",
        "    # Calculate mse with new weights: mse\n",
        "    mse = get_mse(input_data, target, weights)\n",
        "    \n",
        "    # Append the mse to mse_hist\n",
        "    mse_hist.append(mse)\n",
        "\n",
        "# Plot the mse history\n",
        "plt.plot(mse_hist)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS_W8PCIbnKd"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxaRx_3ZP4Tz"
      },
      "source": [
        "#Understanding your data\n",
        "You will soon start building models in Keras to predict wages based on various professional and demographic factors. Before you start building a model, it's good to understand your data by performing some exploratory analysis.\n",
        "\n",
        "The data is pre-loaded into a pandas DataFrame called df. Use the .head() and .describe() methods in the IPython Shell for a quick overview of the DataFrame.\n",
        "\n",
        "The target variable you'll be predicting is wage_per_hour. Some of the predictor variables are binary indicators, where a value of 1 represents True, and 0 represents False.\n",
        "\n",
        "Of the 9 predictor variables in the DataFrame, how many are binary indicators? The min and max values as shown by .describe() will be informative here. How many binary indicator predictors are there?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "I9CQ9lxZUt31",
        "outputId": "5c70f929-4f2d-43c6-9921-374d82d0bf68"
      },
      "source": [
        "#Load the data\n",
        "from google.colab import files # Use to load data on Google Colab\n",
        "uploaded = files.upload() # Use to load data on Google Colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-53b76431-339e-4146-844d-24a162343793\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-53b76431-339e-4146-844d-24a162343793\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zg94a4U4Uv_t",
        "outputId": "bb3e49e1-2cfa-4af9-c2d7-e1756c79ae89"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('hourly_wages.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wage_per_hour</th>\n",
              "      <th>union</th>\n",
              "      <th>education_yrs</th>\n",
              "      <th>experience_yrs</th>\n",
              "      <th>age</th>\n",
              "      <th>female</th>\n",
              "      <th>marr</th>\n",
              "      <th>south</th>\n",
              "      <th>manufacturing</th>\n",
              "      <th>construction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.10</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.95</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.67</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.00</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.50</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   wage_per_hour  union  education_yrs  ...  south  manufacturing  construction\n",
              "0           5.10      0              8  ...      0              1             0\n",
              "1           4.95      0              9  ...      0              1             0\n",
              "2           6.67      0             12  ...      0              1             0\n",
              "3           4.00      0             12  ...      0              0             0\n",
              "4           7.50      0             12  ...      0              0             0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfq86kiCVDT0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "RJweLOnrVECA",
        "outputId": "606c62b3-c2d6-4223-ab92-9940dfd2a985"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wage_per_hour</th>\n",
              "      <th>union</th>\n",
              "      <th>education_yrs</th>\n",
              "      <th>experience_yrs</th>\n",
              "      <th>age</th>\n",
              "      <th>female</th>\n",
              "      <th>marr</th>\n",
              "      <th>south</th>\n",
              "      <th>manufacturing</th>\n",
              "      <th>construction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.024064</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>13.018727</td>\n",
              "      <td>17.822097</td>\n",
              "      <td>36.833333</td>\n",
              "      <td>0.458801</td>\n",
              "      <td>0.655431</td>\n",
              "      <td>0.292135</td>\n",
              "      <td>0.185393</td>\n",
              "      <td>0.044944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.139097</td>\n",
              "      <td>0.384360</td>\n",
              "      <td>2.615373</td>\n",
              "      <td>12.379710</td>\n",
              "      <td>11.726573</td>\n",
              "      <td>0.498767</td>\n",
              "      <td>0.475673</td>\n",
              "      <td>0.455170</td>\n",
              "      <td>0.388981</td>\n",
              "      <td>0.207375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.780000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>11.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>44.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       wage_per_hour       union  ...  manufacturing  construction\n",
              "count     534.000000  534.000000  ...     534.000000    534.000000\n",
              "mean        9.024064    0.179775  ...       0.185393      0.044944\n",
              "std         5.139097    0.384360  ...       0.388981      0.207375\n",
              "min         1.000000    0.000000  ...       0.000000      0.000000\n",
              "25%         5.250000    0.000000  ...       0.000000      0.000000\n",
              "50%         7.780000    0.000000  ...       0.000000      0.000000\n",
              "75%        11.250000    0.000000  ...       0.000000      0.000000\n",
              "max        44.500000    1.000000  ...       1.000000      1.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp35NO7kVUeK"
      },
      "source": [
        "As a start, you'll predict workers wages based on characteristics like their industry, education and level of experience. You can find the dataset in a pandas dataframe called df. For convenience, everything in df except for the target has been converted to a NumPy matrix called predictors. The target, wage_per_hour, is available as a NumPy matrix called target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KJxJwojVlHE"
      },
      "source": [
        "Use the .add() method on model to add a Dense layer.\n",
        "Add 50 units, specify activation='relu', and the input_shape parameter to be the tuple (n_cols,) which means it has n_cols items in each row of data, and any number of rows of data are acceptable as inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udPCHDVDZyVK",
        "outputId": "c6859ad3-9df9-48d5-8619-e01ddfd98cf8"
      },
      "source": [
        "import numpy as np\n",
        "predictors = np.array(df.loc[:, df.columns != 'wage_per_hour'])\n",
        "print(predictors)\n",
        "\n",
        "target = np.array(df['wage_per_hour'])\n",
        "print(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  8 21 ...  0  1  0]\n",
            " [ 0  9 42 ...  0  1  0]\n",
            " [ 0 12  1 ...  0  1  0]\n",
            " ...\n",
            " [ 1 17 25 ...  0  0  0]\n",
            " [ 1 12 13 ...  1  0  0]\n",
            " [ 0 16 33 ...  0  1  0]]\n",
            "[ 5.1   4.95  6.67  4.    7.5  13.07  4.45 19.47 13.28  8.75 11.35 11.5\n",
            "  6.5   6.25 19.98  7.3   8.   22.2   3.65 20.55  5.71  7.    3.75  4.5\n",
            "  9.56  5.75  9.36  6.5   3.35  4.75  8.9   4.    4.7   5.    9.25 10.67\n",
            "  7.61 10.    7.5  12.2   3.35 11.   12.    4.85  4.3   6.   15.    4.85\n",
            "  9.    6.36  9.15 11.    4.5   4.8   4.    5.5   8.4   6.75 10.    5.\n",
            "  6.5  10.75  7.   11.43  4.    9.   13.   12.22  6.28  6.75  3.35 16.\n",
            "  5.25  3.5   4.22  3.    4.   10.    5.   16.   13.98 13.26  6.1   3.75\n",
            "  9.    9.45  5.5   8.93  6.25  9.75  6.73  7.78  2.85  3.35 19.98  8.5\n",
            "  9.75 15.    8.   11.25 14.   10.    6.5   9.83 18.5  12.5  26.   14.\n",
            " 10.5  11.   12.47 12.5  15.    6.    9.5   5.    3.75 12.57  6.88  5.5\n",
            "  7.    4.5   6.5  12.    5.    6.5   6.8   8.75  3.75  4.5   6.    5.5\n",
            " 13.    5.65  4.8   7.    5.25  3.35  8.5   6.    6.75  8.89 14.21 10.78\n",
            "  8.9   7.5   4.5  11.25 13.45  6.    4.62 10.58  5.    8.2   6.25  8.5\n",
            " 24.98 16.65  6.25  4.55 11.25 21.25 12.65  7.5  10.25  3.35 13.45  4.84\n",
            " 26.29  6.58 44.5  15.   11.25  7.   10.   14.53 20.   22.5   3.64 10.62\n",
            " 24.98  6.   19.   13.2  22.5  15.    6.88 11.84 16.14 13.95 13.16  5.3\n",
            "  4.5  10.   10.   10.    9.37  5.8  17.86  1.    8.8   9.   18.16  7.81\n",
            " 10.62  4.5  17.25 10.5   9.22 15.   22.5   4.55  9.   13.33 15.    7.5\n",
            "  4.25 12.5   5.13  3.35 11.11  3.84  6.4   5.56 10.    5.65 11.5   3.5\n",
            "  3.35  4.75 19.98  3.5   4.    7.    6.25  4.5  14.29  5.   13.75 13.71\n",
            "  7.5   3.8   5.    9.42  5.5   3.75  3.5   5.8  12.    5.    8.75 10.\n",
            "  8.5   8.63  9.    5.5  11.11 10.    5.2   8.    3.56  5.2  11.67 11.32\n",
            "  7.5   5.5   5.    7.75  5.25  9.    9.65  5.21  7.   12.16  5.25 10.32\n",
            "  3.35  7.7   9.17  8.43  4.    4.13  3.    4.25  7.53 10.53  5.   15.03\n",
            " 11.25  6.25  3.5   6.85 12.5  12.    6.    9.5   4.1  10.43  5.    7.69\n",
            "  5.5   6.4  12.5   6.25  8.    9.6   9.1   7.5   5.    7.    3.55  8.5\n",
            "  4.5   7.88  5.25  5.    9.33 10.5   7.5   9.5   9.6   5.87 11.02  5.\n",
            "  5.62 12.5  10.81  5.4   7.    4.59  6.   11.71  5.62  5.5   4.85  6.75\n",
            "  4.25  5.75  3.5   3.35 10.62  8.    4.75  8.5   8.85  8.    6.    7.14\n",
            "  3.4   6.    3.75  8.89  4.35 13.1   4.35  3.5   3.8   5.26  3.35 16.26\n",
            "  4.25  4.5   8.    4.    7.96  4.    4.15  5.95  3.6   8.75  3.4   4.28\n",
            "  5.35  5.    7.65  6.94  7.5   3.6   1.75  3.45  9.63  8.49  8.99  3.65\n",
            "  3.5   3.43  5.5   6.93  3.51  3.75  4.17  9.57 14.67 12.5   5.5   5.15\n",
            "  8.    5.83  3.35  7.   10.    8.    6.88  5.55  7.5   8.93  9.    3.5\n",
            "  5.77 25.    6.85  6.5   3.75  3.5   4.5   2.01  4.17 13.    3.98  7.5\n",
            " 13.12  4.    3.95 13.    9.    4.55  9.5   4.5   8.75 10.   18.   24.98\n",
            " 12.05 22.    8.75 22.2  17.25  6.    8.06  9.24 12.   10.61  5.71 10.\n",
            " 17.5  15.    7.78  7.8  10.   24.98 10.28 15.   12.   10.58  5.85 11.22\n",
            "  8.56 13.89  5.71 15.79  7.5  11.25  6.15 13.45  6.25  6.5  12.    8.5\n",
            "  8.    5.75 15.73  9.86 13.51  5.4   6.25  5.5   5.    6.25  5.75 20.5\n",
            "  5.    7.   18.   12.   20.4  22.2  16.42  8.63 19.38 14.   10.   15.95\n",
            " 20.   10.   24.98 11.25 22.83 10.2  10.   14.   12.5   5.79 24.98  4.35\n",
            " 11.25  6.67  8.   18.16 12.    8.89  9.5  13.65 12.   15.   12.67  7.38\n",
            " 15.56  7.45  6.25  6.25  9.37 22.5   7.5   7.    5.75  7.67 12.5  16.\n",
            " 11.79 11.36  6.1  23.25 19.88 15.38]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoFV9VzMVWxq"
      },
      "source": [
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "\n",
        "# Set up the model: model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first layer\n",
        "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
        "\n",
        "#the input_shape parameter to be the tuple (n_cols,) which means it has n_cols items in each row of data, and any number of rows of data are acceptable as inputs.\n",
        "\n",
        "# Add the second layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Upbtaxez-j",
        "outputId": "b873bb15-0d0c-4322-a03e-322ea33ba806"
      },
      "source": [
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Specify the model\n",
        "n_cols = predictors.shape[1]\n",
        "model = Sequential()\n",
        "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Verify that model contains information from compiling\n",
        "print(\"Loss function: \" + model.loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss function: mean_squared_error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNPepWB4e8ro",
        "outputId": "7c702860-56b9-464a-ceef-70f0e1711dfa"
      },
      "source": [
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Specify the model\n",
        "n_cols = predictors.shape[1]\n",
        "model = Sequential()\n",
        "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors, target)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 14s 2ms/step - loss: 287.9079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b8c40be90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrYkNRIhgJOo"
      },
      "source": [
        "Classification on Titanic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7TxugOmgbe5"
      },
      "source": [
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert the target to categorical: target\n",
        "target = to_categorical(df.survived)\n",
        "\n",
        "# Set up the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first layer\n",
        "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='sgd', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors, target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtbn0xXngI3a"
      },
      "source": [
        "# Specify, compile, and fit the model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(optimizer='sgd', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(predictors, target)\n",
        "\n",
        "# Calculate predictions: predictions\n",
        "predictions = model.predict(pred_data)\n",
        "\n",
        "# Calculate predicted probability of survival: predicted_prob_true\n",
        "predicted_prob_true = predictions[:,1]\n",
        "\n",
        "# print predicted_prob_true\n",
        "print(predicted_prob_true)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEvhF8TtWwoR"
      },
      "source": [
        "#Changing optimization parameters\n",
        "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good.\n",
        "\n",
        "For these exercises, we've pre-loaded the predictors and target values from your previous classification models (predicting who would survive on the Titanic). You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function get_new_model() that creates an unoptimized model to optimize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWkRfRfYW0Fi"
      },
      "source": [
        "# Import the SGD optimizer\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Create list of learning rates: lr_to_test\n",
        "lr_to_test = [.000001, 0.01, 1]\n",
        "\n",
        "# Loop over learning rates\n",
        "for lr in lr_to_test:\n",
        "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
        "    \n",
        "    # Build new model to test, unaffected by previous models\n",
        "    model = get_new_model()\n",
        "    \n",
        "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
        "    my_optimizer = SGD(lr=lr)\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')\n",
        "    \n",
        "    # Fit the model\n",
        "    model.fit(predictors, target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdB88rsBt-tu"
      },
      "source": [
        "Evaluating model accuracy on validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lOdkR6guCiw"
      },
      "source": [
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Specify the model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(predictors, target, validation_split=0.3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6ilSQcJvC5h"
      },
      "source": [
        "#Early stopping: Optimizing the optimization\n",
        "Now that you know how to monitor your model performance throughout optimization, you can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, you can also set a high value for epochs in your call to .fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khPV4CQ7vKPy"
      },
      "source": [
        "# Import EarlyStopping\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Specify the model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors, target, epochs=30, validation_split=0.3, callbacks=[early_stopping_monitor])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FIyOA27vZNp"
      },
      "source": [
        "Because optimization will automatically stop when it is no longer helpful, it is okay to specify the maximum number of epochs as 30 rather than using the default of 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qf13YnavjDj"
      },
      "source": [
        "Experimenting with wider networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55dP_M0zvg9C"
      },
      "source": [
        "# Define early_stopping_monitor\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "# Create the new model: model_2\n",
        "model_2 = Sequential()\n",
        "\n",
        "# Add the first and second layers\n",
        "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model_2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile model_2\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit model_1\n",
        "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Fit model_2\n",
        "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MEvFva-vsd6"
      },
      "source": [
        "#Adding layers to a network\n",
        "You've seen how to experiment with wider networks. In this exercise, you'll try a deeper network (more hidden layers)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFK7pXhEvu17"
      },
      "source": [
        "# The input shape to use in the first hidden layer\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Create the new model: model_2\n",
        "model_2 = Sequential()\n",
        "\n",
        "# Add the first, second, and third hidden layers\n",
        "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
        "model_2.add(Dense(50, activation='relu'))\n",
        "model_2.add(Dense(50, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model_2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile model_2\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit model 1\n",
        "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Fit model 2\n",
        "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K4ewBOT0KYP"
      },
      "source": [
        "#Building your own digit recognition model\n",
        "You've reached the final exercise of the course - you now know everything you need to build an accurate model to recognize handwritten digits!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5SFw6wS0Q35"
      },
      "source": [
        "# Create the model: model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first hidden layer\n",
        "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
        "\n",
        "# Add the second hidden layer\n",
        "model.add(Dense(50, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, validation_split=0.3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp9NQO_L4OPm"
      },
      "source": [
        "#Activation Functions\n",
        "The choice of activation function in the hidden layer will control how well the network model learns the training dataset. \n",
        "The choice of activation function in the output layer will define the type of predictions the model can make.\n",
        "It is used to add non-linearity to your predictions\n",
        "\n",
        "For hidden layer, use\n",
        "1. RELU /Rectified Linear activation\n",
        "2. Logistic or sigmoid\n",
        "3. TanH\n",
        "\n",
        "# RELU \n",
        "max(0.0, x)\n",
        "This means that if the input value (x) is negative, then a value 0.0 is returned, otherwise, the value is returned.\n",
        "\n",
        "# Sigmoid or Logistic\n",
        "The function takes any real value as input and outputs values in the range 0 to 1. The larger the input (more positive), the closer the output value will be to 1.0, whereas the smaller the input (more negative), the closer the output will be to 0.0.\n",
        "\n",
        "#Tanh Hidden Layer Activation Function\n",
        "The function takes any real value as input and outputs values in the range -1 to 1. The larger the input (more positive), the closer the output value will be to 1.0, whereas the smaller the input (more negative), the closer the output will be to -1.0.\n",
        "\n",
        "#Activation for Output Layers\n",
        "Linear\n",
        "Logistic (Sigmoid)\n",
        "Softmax\n",
        "\n",
        "#Linear Output Activation Function\n",
        "The linear activation function is also called identity (multiplied by 1.0) or no activation.\n",
        "\n",
        "#Softmax Output Activation Function\n",
        "The softmax function outputs a vector of values that sum to 1.0 that can be interpreted as probabilities of class membership.\n",
        "\n",
        "In output layer,\n",
        "If your problem is a **regression problem**, you should use a linear activation function.\n",
        "If, a **classification problem**,\n",
        "Binary Classification: One node, sigmoid activation.\n",
        "Multiclass Classification: One node per class, softmax activation.\n",
        "Multilabel Classification: One node per class, sigmoid activation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po57ldFoBb1U"
      },
      "source": [
        "#Dying Neuron problem\n",
        "ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero\n",
        "\n",
        "Once a ReLU ends up in this state, it is unlikely to recover, because the function gradient at 0 is also 0, so gradient descent learning will not alter the weights. \"Leaky\" ReLUs with a small positive gradient for negative inputs (y=0.01x when x < 0 say) are one attempt to address this issue and give a chance to recover.\n",
        "\n",
        "The sigmoid and tanh neurons can suffer from similar problems as their values saturate, but there is always at least a small gradient allowing them to recover in the long term."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jppb3WafBybD"
      },
      "source": [
        "#Vanishing Gradient\n",
        "The problem:\n",
        "\n",
        "Gradient based methods learn a parameter's value by understanding how a small change in the parameter's value will affect the network's output. If a change in the parameter's value causes very small change in the network's output - the network just can't learn the parameter effectively, which is a problem.\n",
        "\n",
        "As more layers using certain activation functions are added to neural networks, the gradients of the loss function approaches zero, making the network hard to train.\n",
        "Why:\n",
        "Certain activation functions, like the sigmoid function, squishes a large input space into a small input space between 0 and 1. Therefore, a large change in the input of the sigmoid function will cause a small change in the output. Hence, the derivative becomes small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIaHy2H_BA3I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}